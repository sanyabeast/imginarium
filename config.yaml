# config.yaml Example Structure
tags:
  subject:
    - cat
    - dog
    - person
    - landscape
    - abstract
    - object
  setting:
    - city
    - forest
    - beach
    - space
    - indoor
    - studio
  mood:
    - happy
    - sad
    - dramatic
    - peaceful
    - energetic
    - mysterious
  style:
    - photorealistic
    - illustration
    - painting
    - cartoon
    - 3d render
    - vintage

lm_studio:
  api_base: "http://localhost:1234/v1" # Replace with your LM Studio API endpoint
  model: "gemma-3-4b-it" # Default model to use
  prompt_template: |
    Generate a detailed image prompt for a stock photo based on these tags: {tags}.
    The prompt should be suitable for an AI image generator like Stable Diffusion.
    Focus on visual details, composition, and lighting.
    Prompt:

comfy_ui:
  server_address: "127.0.0.1:8188" # Replace with your ComfyUI server address
  client_id: "" # Will be generated by the script
  output_directory: "output_images" # Directory to save generated images

# Default expected node titles (can be adjusted in the script if needed):
# - Prompt Input Node Title: "CLIP Text Encode (Prompt)"
# - Image Output Node Title: "Save Image"
comfy_workflow: |
  {
    "6": {
      "inputs": {
        "text": "{PROMPT}",
        "clip": [
          "30",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Positive Prompt)"
      }
    },
    "8": {
      "inputs": {
        "samples": [
          "31",
          0
        ],
        "vae": [
          "30",
          2
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "9": {
      "inputs": {
        "filename_prefix": "flux/image",
        "images": [
          "8",
          0
        ]
      },
      "class_type": "SaveImage",
      "_meta": {
        "title": "Save Image"
      }
    },
    "27": {
      "inputs": {
        "width": 1024,
        "height": 1024,
        "batch_size": 1
      },
      "class_type": "EmptySD3LatentImage",
      "_meta": {
        "title": "EmptySD3LatentImage"
      }
    },
    "30": {
      "inputs": {
        "ckpt_name": "flux.1d-fp8.safetensors"
      },
      "class_type": "CheckpointLoaderSimple",
      "_meta": {
        "title": "Load Checkpoint"
      }
    },
    "31": {
      "inputs": {
        "seed": {SEED},
        "steps": {STEPS},
        "cfg": 1,
        "sampler_name": "euler",
        "scheduler": "simple",
        "denoise": 1,
        "model": [
          "30",
          0
        ],
        "positive": [
          "35",
          0
        ],
        "negative": [
          "33",
          0
        ],
        "latent_image": [
          "27",
          0
        ]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "33": {
      "inputs": {
        "text": "{NEGATIVE_PROMPT}",
        "clip": [
          "30",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Negative Prompt)"
      }
    },
    "35": {
      "inputs": {
        "guidance": 3.5,
        "conditioning": [
          "6",
          0
        ]
      },
      "class_type": "FluxGuidance",
      "_meta": {
        "title": "FluxGuidance"
      }
    }
  }